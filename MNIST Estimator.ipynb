{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with np.load(os.path.join('data','mnist-60k.npz'), allow_pickle=False) as npz_file:\n",
    "    # Load items into a dictionary\n",
    "    mnist = dict(npz_file.items())\n",
    "    \n",
    "X = mnist['data'].astype(np.float32).reshape(-1, 28, 28, 1)\n",
    "y = mnist['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr (54000, 28, 28, 1)\n",
      "X_te (3000, 28, 28, 1)\n",
      "X_cv (3000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# scale and split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create train/test sets\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X,y,test_size=0.1, random_state=0)\n",
    "\n",
    "# Split again into validation/test sets\n",
    "X_cv, X_te, y_cv, y_te = train_test_split(X_te, y_te,test_size=0.5, random_state=0)\n",
    "\n",
    "print(\"X_tr\", X_tr.shape)\n",
    "print(\"X_te\", X_te.shape)\n",
    "print(\"X_cv\", X_cv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With an Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Model Function\n",
    "\n",
    "def model_fn(features, labels, mode = \"PREDICT\"):\n",
    "    input_layer = tf.reshape(features[\"X\"], [-1, 28, 28, 1])\n",
    "    y = labels\n",
    "    \n",
    "    #training = tf.placeholder(dtype=tf.bool)\n",
    "\n",
    "    # create global step for decaying learning rate\n",
    "    #global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "    # Decay the learning rate - \n",
    "    #learning_rate = tf.train.exponential_decay(0.001,               # start at 0.001\n",
    "    #                                           global_step, \n",
    "    #                                           2000,                # 2000 steps\n",
    "    #                                           0.9,                 # 0.95 increment\n",
    "    #                                           staircase=True)\n",
    "\n",
    "    # Convolutional layer 1 \n",
    "    conv1 = tf.layers.conv2d(\n",
    "        input_layer,                           # Input data\n",
    "        filters=32,                  # 32 filters\n",
    "        kernel_size=(5, 5),          # Kernel size: 5x5\n",
    "        strides=(1, 1),              # Stride: 1\n",
    "        padding='SAME',              # \"same\" padding\n",
    "        activation=tf.nn.relu,       # ReLU\n",
    "        kernel_initializer=tf.truncated_normal_initializer(stddev=5e-2, seed=0), # Small standard deviation\n",
    "        name='conv1'                  # Add name\n",
    "    )\n",
    "\n",
    "    # Max pooling layer 1\n",
    "    pool1 = tf.layers.max_pooling2d(\n",
    "        conv1,                       # Input\n",
    "        pool_size=(2, 2),            # Pool size: 2x\n",
    "        strides=(2, 2),              # Stride: 2\n",
    "        padding='SAME',              # \"same\" padding\n",
    "        name='pool1'\n",
    "    )\n",
    "\n",
    "    # Convolutional layer 2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        pool1,                       # Input\n",
    "        filters=64,                  # 64 filters\n",
    "        kernel_size=(5, 5),          # Kernel size: 5x5\n",
    "        strides=(1, 1),              # Stride: 1\n",
    "        padding='SAME',              # \"same\" padding\n",
    "        activation=tf.nn.relu,       # ReLU\n",
    "        kernel_initializer=tf.truncated_normal_initializer(stddev=5e-2, seed=0),    # Small standard deviation\n",
    "        name='conv2'                 # Add name\n",
    "    )\n",
    "\n",
    "    # Max pooling layer 2 (2x2, stride: 2) - TUNED\n",
    "    pool2 = tf.layers.max_pooling2d(\n",
    "        conv2,                       # input\n",
    "        pool_size=(2, 2),            # pool size 2x2\n",
    "        strides=(2, 2),              # stride 2\n",
    "        padding='SAME'\n",
    "    )\n",
    "\n",
    "    # Flatten output\n",
    "    flat_output = tf.contrib.layers.flatten(pool2)\n",
    "\n",
    "    # Fully connected layer\n",
    "    fc1 = tf.layers.dense(\n",
    "        flat_output,                 # input\n",
    "        1024,                         # 256 hidden units\n",
    "        activation=tf.nn.relu,       # ReLU\n",
    "        kernel_initializer=tf.variance_scaling_initializer(scale=2, seed=0),\n",
    "        bias_initializer=tf.zeros_initializer()\n",
    "    )\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        fc1 = tf.layers.dropout(fc1, rate=0.40, seed=1)\n",
    "\n",
    "    # logits\n",
    "    logits = tf.layers.dense(\n",
    "        fc1,                         # input\n",
    "        10,                           # One output unit per category\n",
    "        activation=None,             # No activation function\n",
    "        kernel_initializer=tf.variance_scaling_initializer(scale=1, seed=0),\n",
    "        bias_initializer=tf.zeros_initializer()\n",
    "    )\n",
    "\n",
    "    # predictions\n",
    "    predictions = {\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=logits)\n",
    "    accuracy = tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(loss=loss,global_step=tf.train.get_global_step())\n",
    "\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    ## Else if mode == \"EVAL\"\n",
    "    \n",
    "    # Compute predictions and accuracy\n",
    "    #is_correct = tf.equal(y, predictions['classes'])\n",
    "    #accuracy = tf.reduce_mean(tf.cast(is_correct, dtype=tf.float32))\n",
    "\n",
    "    eval_metric_ops = {\n",
    "      \"accuracy\": accuracy,\n",
    "      #\"cost\": loss,  \n",
    "    }\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './mnist_convnet_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': device_count {\n",
      "  key: \"GPU\"\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001C0F74F79E8>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto(\n",
    "    # uncomment to run on CPU\n",
    "    device_count = {'GPU': 0}\n",
    ")\n",
    "estimator_config = tf.estimator.RunConfig(session_config=config)\n",
    "\n",
    "# create the Estimator\n",
    "mnist_classifier = tf.estimator.Estimator(model_fn=model_fn, model_dir=\"./mnist_convnet_model\", config=estimator_config)\n",
    "\n",
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_tr},\n",
    "    y=y_tr,\n",
    "    batch_size=128,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_convnet_model\\model.ckpt-25002\n",
      "INFO:tensorflow:Saving checkpoints for 25003 into ./mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00087020826, step = 25003\n",
      "INFO:tensorflow:global_step/sec: 3.6752\n",
      "INFO:tensorflow:loss = 0.00087107084, step = 25103 (27.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.78393\n",
      "INFO:tensorflow:loss = 0.001524379, step = 25203 (26.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.71335\n",
      "INFO:tensorflow:loss = 0.0015444546, step = 25303 (26.914 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.72958\n",
      "INFO:tensorflow:loss = 0.003645241, step = 25403 (26.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.64249\n",
      "INFO:tensorflow:loss = 0.0015865283, step = 25503 (27.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.73841\n",
      "INFO:tensorflow:loss = 0.00087912916, step = 25603 (26.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.804\n",
      "INFO:tensorflow:loss = 0.0017781884, step = 25703 (26.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.84012\n",
      "INFO:tensorflow:loss = 0.0007145401, step = 25803 (26.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.7494\n",
      "INFO:tensorflow:loss = 0.0022169198, step = 25903 (26.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.72184\n",
      "INFO:tensorflow:loss = 0.0029323094, step = 26003 (26.868 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.54759\n",
      "INFO:tensorflow:loss = 0.0016604587, step = 26103 (28.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.76145\n",
      "INFO:tensorflow:loss = 0.00093510747, step = 26203 (26.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.71972\n",
      "INFO:tensorflow:loss = 0.0008393193, step = 26303 (26.888 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.63461\n",
      "INFO:tensorflow:loss = 0.0016547653, step = 26403 (27.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.75831\n",
      "INFO:tensorflow:loss = 0.000441831, step = 26503 (26.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.59205\n",
      "INFO:tensorflow:loss = 0.0027389624, step = 26603 (27.830 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.76883\n",
      "INFO:tensorflow:loss = 0.0013080856, step = 26703 (26.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.48037\n",
      "INFO:tensorflow:loss = 0.0009443311, step = 26803 (28.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.50821\n",
      "INFO:tensorflow:loss = 0.0028198464, step = 26903 (28.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.515\n",
      "INFO:tensorflow:loss = 0.0010614777, step = 27003 (28.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.41902\n",
      "INFO:tensorflow:loss = 0.0008516585, step = 27103 (29.238 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 27201 into ./mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 3.53024\n",
      "INFO:tensorflow:loss = 0.00080725976, step = 27203 (28.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.68283\n",
      "INFO:tensorflow:loss = 0.0010625783, step = 27303 (27.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.71246\n",
      "INFO:tensorflow:loss = 0.0018649577, step = 27403 (26.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.92896\n",
      "INFO:tensorflow:loss = 0.0032979527, step = 27503 (25.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.94517\n",
      "INFO:tensorflow:loss = 0.004196562, step = 27603 (25.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.94161\n",
      "INFO:tensorflow:loss = 0.00066102156, step = 27703 (25.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.91697\n",
      "INFO:tensorflow:loss = 0.00126108, step = 27803 (25.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.75155\n",
      "INFO:tensorflow:loss = 0.0034367582, step = 27903 (26.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.70139\n",
      "INFO:tensorflow:loss = 0.0011927162, step = 28003 (27.033 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.71834\n",
      "INFO:tensorflow:loss = 0.0014737904, step = 28103 (26.878 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.74319\n",
      "INFO:tensorflow:loss = 0.00067459146, step = 28203 (26.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.67759\n",
      "INFO:tensorflow:loss = 0.0016778469, step = 28303 (27.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.69641\n",
      "INFO:tensorflow:loss = 0.0012637025, step = 28403 (27.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.8212\n",
      "INFO:tensorflow:loss = 0.00013149856, step = 28503 (26.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.90409\n",
      "INFO:tensorflow:loss = 0.00276865, step = 28603 (25.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.93596\n",
      "INFO:tensorflow:loss = 0.002942112, step = 28703 (25.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.88245\n",
      "INFO:tensorflow:loss = 0.00090300187, step = 28803 (25.758 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.65653\n",
      "INFO:tensorflow:loss = 0.0019383096, step = 28903 (27.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.66778\n",
      "INFO:tensorflow:loss = 0.0023685927, step = 29003 (27.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.53075\n",
      "INFO:tensorflow:loss = 0.0012508226, step = 29103 (28.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.75777\n",
      "INFO:tensorflow:loss = 0.00048827642, step = 29203 (26.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.72007\n",
      "INFO:tensorflow:loss = 0.0016456619, step = 29303 (26.883 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.73029\n",
      "INFO:tensorflow:loss = 0.0012311607, step = 29403 (26.806 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 29461 into ./mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 3.47824\n",
      "INFO:tensorflow:loss = 0.0005291101, step = 29503 (28.751 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.40637\n",
      "INFO:tensorflow:loss = 0.0006680455, step = 29603 (29.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.57551\n",
      "INFO:tensorflow:loss = 0.0023111736, step = 29703 (27.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.77234\n",
      "INFO:tensorflow:loss = 0.000605378, step = 29803 (26.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.55339\n",
      "INFO:tensorflow:loss = 0.00122712, step = 29903 (28.136 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30002 into ./mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0017612184.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x277a0e6bbe0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train \n",
    "mnist_classifier.train(input_fn=train_input_fn, steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-02-10-13:51:50\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_convnet_model\\model.ckpt-30002\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-10-13:51:56\n",
      "INFO:tensorflow:Saving dict for global step 30002: accuracy = 0.988, global_step = 30002, loss = 0.05056255\n",
      "{'accuracy': 0.988, 'loss': 0.05056255, 'global_step': 30002}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and print results\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_cv},\n",
    "    y=y_cv,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-02-10-13:37:50\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_convnet_model\\model.ckpt-30002\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-10-13:37:53\n",
      "INFO:tensorflow:Saving dict for global step 30002: accuracy = 0.9853333, global_step = 30002, loss = 0.064221136\n",
      "{'accuracy': 0.9853333, 'loss': 0.064221136, 'global_step': 30002}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and print results\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_te},\n",
    "    y=y_te,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "test_results = mnist_classifier.evaluate(input_fn=test_input_fn)\n",
    "\n",
    "print(test_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
