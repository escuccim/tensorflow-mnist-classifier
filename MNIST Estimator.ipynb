{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "with np.load(os.path.join('data','mnist-60k.npz'), allow_pickle=False) as npz_file:\n",
    "    # Load items into a dictionary\n",
    "    mnist = dict(npz_file.items())\n",
    "    \n",
    "X = mnist['data'].astype(np.float32).reshape(-1, 28, 28, 1)\n",
    "y = mnist['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr (54000, 28, 28, 1)\n",
      "X_te (3000, 28, 28, 1)\n",
      "X_cv (3000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# scale and split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create train/test sets\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X,y,test_size=0.1, random_state=0)\n",
    "\n",
    "# Split again into validation/test sets\n",
    "X_cv, X_te, y_cv, y_te = train_test_split(X_te, y_te,test_size=0.5, random_state=0)\n",
    "\n",
    "print(\"X_tr\", X_tr.shape)\n",
    "print(\"X_te\", X_te.shape)\n",
    "print(\"X_cv\", X_cv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With an Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Model Function\n",
    "\n",
    "def model_fn(features, labels, mode = \"PREDICT\"):\n",
    "    input_layer = tf.reshape(features[\"X\"], [-1, 28, 28, 1])\n",
    "    y = labels\n",
    "    \n",
    "    # Convolutional layer 1 \n",
    "    conv1 = tf.layers.conv2d(\n",
    "        input_layer,                           # Input data\n",
    "        filters=32,                  # 32 filters\n",
    "        kernel_size=(5, 5),          # Kernel size: 5x5\n",
    "        strides=(1, 1),              # Stride: 1\n",
    "        padding='SAME',              # \"same\" padding\n",
    "        activation=tf.nn.relu,       # ReLU\n",
    "        kernel_initializer=tf.truncated_normal_initializer(stddev=5e-2, seed=0), # Small standard deviation\n",
    "        name='conv1'                  # Add name\n",
    "    )\n",
    "\n",
    "    # Max pooling layer 1\n",
    "    pool1 = tf.layers.max_pooling2d(\n",
    "        conv1,                       # Input\n",
    "        pool_size=(2, 2),            # Pool size: 2x\n",
    "        strides=(2, 2),              # Stride: 2\n",
    "        padding='SAME',              # \"same\" padding\n",
    "        name='pool1'\n",
    "    )\n",
    "\n",
    "    # Convolutional layer 2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        pool1,                       # Input\n",
    "        filters=64,                  # 64 filters\n",
    "        kernel_size=(5, 5),          # Kernel size: 5x5\n",
    "        strides=(1, 1),              # Stride: 1\n",
    "        padding='SAME',              # \"same\" padding\n",
    "        activation=tf.nn.relu,       # ReLU\n",
    "        kernel_initializer=tf.truncated_normal_initializer(stddev=5e-2, seed=0),    # Small standard deviation\n",
    "        name='conv2'                 # Add name\n",
    "    )\n",
    "\n",
    "    # Max pooling layer 2 (2x2, stride: 2) - TUNED\n",
    "    pool2 = tf.layers.max_pooling2d(\n",
    "        conv2,                       # input\n",
    "        pool_size=(2, 2),            # pool size 2x2\n",
    "        strides=(2, 2),              # stride 2\n",
    "        padding='SAME'\n",
    "    )\n",
    "\n",
    "    # Flatten output\n",
    "    flat_output = tf.contrib.layers.flatten(pool2)\n",
    "\n",
    "    # Fully connected layer\n",
    "    fc1 = tf.layers.dense(\n",
    "        flat_output,                 # input\n",
    "        1024,                         # 256 hidden units\n",
    "        activation=tf.nn.relu,       # ReLU\n",
    "        kernel_initializer=tf.variance_scaling_initializer(scale=2, seed=0),\n",
    "        bias_initializer=tf.zeros_initializer()\n",
    "    )\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        fc1 = tf.layers.dropout(fc1, rate=0.70, seed=1)\n",
    "\n",
    "    # logits\n",
    "    logits = tf.layers.dense(\n",
    "        fc1,                         # input\n",
    "        10,                           # One output unit per category\n",
    "        activation=None,             # No activation function\n",
    "        kernel_initializer=tf.variance_scaling_initializer(scale=1, seed=0),\n",
    "        bias_initializer=tf.zeros_initializer()\n",
    "    )\n",
    "\n",
    "    # predictions\n",
    "    predictions = {\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=logits)\n",
    "    accuracy = tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(loss=loss,global_step=tf.train.get_global_step())\n",
    "\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    ## Else if mode == \"EVAL\"\n",
    "    \n",
    "    # Compute predictions and accuracy\n",
    "    #is_correct = tf.equal(y, predictions['classes'])\n",
    "    #accuracy = tf.reduce_mean(tf.cast(is_correct, dtype=tf.float32))\n",
    "\n",
    "    eval_metric_ops = {\n",
    "      \"accuracy\": accuracy,\n",
    "      #\"cost\": loss,  \n",
    "    }\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './mnist_convnet_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.6\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001FD5D017320>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto(\n",
    "    # comment to run on GPU\n",
    "    #device_count = {'GPU': 0}\n",
    ")\n",
    "\n",
    "# bring GPU memory usage down to a level where it won't crash\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
    "\n",
    "# create a config\n",
    "estimator_config = tf.estimator.RunConfig(session_config=config)\n",
    "\n",
    "# create the Estimator\n",
    "mnist_classifier = tf.estimator.Estimator(model_fn=model_fn, model_dir=\"./mnist_convnet_model\", config=estimator_config)\n",
    "\n",
    "# Create a training function\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_tr},\n",
    "    y=y_tr,\n",
    "    batch_size=32,       # small batch size so GPU doesn't crash\n",
    "    num_epochs=None,     \n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_convnet_model\\model.ckpt-35004\n",
      "INFO:tensorflow:Saving checkpoints for 35005 into ./mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0002528891, step = 35005\n",
      "INFO:tensorflow:global_step/sec: 37.2378\n",
      "INFO:tensorflow:loss = 7.2806724e-05, step = 35105 (2.686 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.8225\n",
      "INFO:tensorflow:loss = 6.1168685e-05, step = 35205 (2.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.974\n",
      "INFO:tensorflow:loss = 0.00022460984, step = 35305 (2.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.7172\n",
      "INFO:tensorflow:loss = 0.0010341842, step = 35405 (2.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.7774\n",
      "INFO:tensorflow:loss = 0.0016988354, step = 35505 (2.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.7173\n",
      "INFO:tensorflow:loss = 0.0002186491, step = 35605 (2.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.7621\n",
      "INFO:tensorflow:loss = 0.00038186388, step = 35705 (2.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.9135\n",
      "INFO:tensorflow:loss = 0.00059225183, step = 35805 (2.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.5381\n",
      "INFO:tensorflow:loss = 0.00012673346, step = 35905 (2.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.6574\n",
      "INFO:tensorflow:loss = 0.0015610389, step = 36005 (2.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.7376\n",
      "INFO:tensorflow:loss = 0.00010283384, step = 36105 (2.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.8879\n",
      "INFO:tensorflow:loss = 0.00016420119, step = 36205 (2.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.9976\n",
      "INFO:tensorflow:loss = 0.00017974961, step = 36305 (2.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.1988\n",
      "INFO:tensorflow:loss = 5.9559654e-05, step = 36405 (2.841 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.4703\n",
      "INFO:tensorflow:loss = 0.0007714111, step = 36505 (2.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.1989\n",
      "INFO:tensorflow:loss = 0.0001482329, step = 36605 (2.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.3431\n",
      "INFO:tensorflow:loss = 0.0006153028, step = 36705 (2.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.0236\n",
      "INFO:tensorflow:loss = 0.0020200715, step = 36805 (3.028 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.904\n",
      "INFO:tensorflow:loss = 0.00022240132, step = 36905 (3.039 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.9299\n",
      "INFO:tensorflow:loss = 0.0015912249, step = 37005 (3.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.1657\n",
      "INFO:tensorflow:loss = 0.00038969636, step = 37105 (3.025 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.8482\n",
      "INFO:tensorflow:loss = 0.00014123821, step = 37205 (3.035 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.9584\n",
      "INFO:tensorflow:loss = 5.8486166e-06, step = 37305 (3.033 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.9908\n",
      "INFO:tensorflow:loss = 1.1077959e-05, step = 37405 (3.031 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.0892\n",
      "INFO:tensorflow:loss = 0.0004831545, step = 37505 (3.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.1657\n",
      "INFO:tensorflow:loss = 8.364054e-05, step = 37605 (3.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.0672\n",
      "INFO:tensorflow:loss = 4.710347e-05, step = 37705 (3.024 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.0563\n",
      "INFO:tensorflow:loss = 1.83415e-05, step = 37805 (3.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.0449\n",
      "INFO:tensorflow:loss = 0.00041429492, step = 37905 (3.025 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.9472\n",
      "INFO:tensorflow:loss = 0.0009703376, step = 38005 (3.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.0158\n",
      "INFO:tensorflow:loss = 0.001836048, step = 38105 (3.028 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.7638\n",
      "INFO:tensorflow:loss = 0.0005884732, step = 38205 (3.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.0236\n",
      "INFO:tensorflow:loss = 0.00080642547, step = 38305 (3.028 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.8713\n",
      "INFO:tensorflow:loss = 0.0009624067, step = 38405 (3.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.9475\n",
      "INFO:tensorflow:loss = 0.0020426116, step = 38505 (3.035 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.0127\n",
      "INFO:tensorflow:loss = 0.0008996096, step = 38605 (3.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.6887\n",
      "INFO:tensorflow:loss = 2.4129997e-05, step = 38705 (3.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.9582\n",
      "INFO:tensorflow:loss = 6.649473e-06, step = 38805 (3.034 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.8487\n",
      "INFO:tensorflow:loss = 5.142353e-05, step = 38905 (3.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.0257\n",
      "INFO:tensorflow:loss = 0.00019617153, step = 39005 (3.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.0454\n",
      "INFO:tensorflow:loss = 0.002002086, step = 39105 (3.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.0782\n",
      "INFO:tensorflow:loss = 0.0024416808, step = 39205 (3.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.98\n",
      "INFO:tensorflow:loss = 0.0004908801, step = 39305 (3.032 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.9255\n",
      "INFO:tensorflow:loss = 0.0015245941, step = 39405 (3.038 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.0237\n",
      "INFO:tensorflow:loss = 0.00033787108, step = 39505 (3.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.8509\n",
      "INFO:tensorflow:loss = 0.00025523952, step = 39605 (3.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.002\n",
      "INFO:tensorflow:loss = 0.002942177, step = 39705 (3.030 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.9365\n",
      "INFO:tensorflow:loss = 3.1984157e-05, step = 39805 (3.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.9406\n",
      "INFO:tensorflow:loss = 0.00010253736, step = 39905 (3.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.6353\n",
      "INFO:tensorflow:loss = 3.2172095e-05, step = 40005 (3.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.6673\n",
      "INFO:tensorflow:loss = 0.00093099877, step = 40105 (3.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.5733\n",
      "INFO:tensorflow:loss = 0.0014288613, step = 40205 (3.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.7137\n",
      "INFO:tensorflow:loss = 0.000817142, step = 40305 (3.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.6233\n",
      "INFO:tensorflow:loss = 0.0003077051, step = 40405 (3.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.5003\n",
      "INFO:tensorflow:loss = 0.00094113476, step = 40505 (3.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.6197\n",
      "INFO:tensorflow:loss = 0.0003517923, step = 40605 (3.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.5334\n",
      "INFO:tensorflow:loss = 3.7474852e-05, step = 40705 (3.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.7334\n",
      "INFO:tensorflow:loss = 0.0011791983, step = 40805 (3.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.6146\n",
      "INFO:tensorflow:loss = 0.00016063405, step = 40905 (3.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.4403\n",
      "INFO:tensorflow:loss = 0.00037800978, step = 41005 (3.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.6634\n",
      "INFO:tensorflow:loss = 0.0018733479, step = 41105 (3.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2385\n",
      "INFO:tensorflow:loss = 0.0012755421, step = 41205 (9.758 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.49074\n",
      "INFO:tensorflow:loss = 0.0003174456, step = 41305 (18.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.45942\n",
      "INFO:tensorflow:loss = 0.0009177885, step = 41405 (18.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.44129\n",
      "INFO:tensorflow:loss = 0.0007252174, step = 41505 (18.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.42749\n",
      "INFO:tensorflow:loss = 0.0010862258, step = 41605 (18.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.43561\n",
      "INFO:tensorflow:loss = 0.00035284364, step = 41705 (18.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.41974\n",
      "INFO:tensorflow:loss = 0.00049124815, step = 41805 (18.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.41591\n",
      "INFO:tensorflow:loss = 0.0026782304, step = 41905 (18.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.42357\n",
      "INFO:tensorflow:loss = 0.0004225505, step = 42005 (18.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.43507\n",
      "INFO:tensorflow:loss = 0.0014456961, step = 42105 (18.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.43928\n",
      "INFO:tensorflow:loss = 0.00010444295, step = 42205 (18.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.44827\n",
      "INFO:tensorflow:loss = 0.0012095149, step = 42305 (18.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.45275\n",
      "INFO:tensorflow:loss = 0.0012657031, step = 42405 (18.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.7101\n",
      "INFO:tensorflow:loss = 6.227734e-05, step = 42505 (6.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.9133\n",
      "INFO:tensorflow:loss = 0.0007666155, step = 42605 (2.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.8682\n",
      "INFO:tensorflow:loss = 0.0005067437, step = 42705 (2.572 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 38.853\n",
      "INFO:tensorflow:loss = 0.00020217139, step = 42805 (2.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.8674\n",
      "INFO:tensorflow:loss = 0.00029370555, step = 42905 (2.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.0349\n",
      "INFO:tensorflow:loss = 0.0019593288, step = 43005 (2.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.7924\n",
      "INFO:tensorflow:loss = 0.0005245799, step = 43105 (2.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.7323\n",
      "INFO:tensorflow:loss = 0.00023317344, step = 43205 (2.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.8679\n",
      "INFO:tensorflow:loss = 0.0020530154, step = 43305 (2.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.7886\n",
      "INFO:tensorflow:loss = 0.0002627341, step = 43405 (2.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.6522\n",
      "INFO:tensorflow:loss = 0.0014823888, step = 43505 (2.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.9133\n",
      "INFO:tensorflow:loss = 0.00013957891, step = 43605 (2.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.8528\n",
      "INFO:tensorflow:loss = 0.0016724004, step = 43705 (2.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.6812\n",
      "INFO:tensorflow:loss = 0.00057606015, step = 43805 (2.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.8224\n",
      "INFO:tensorflow:loss = 0.00042724315, step = 43905 (2.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.9236\n",
      "INFO:tensorflow:loss = 0.00066338235, step = 44005 (2.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.7867\n",
      "INFO:tensorflow:loss = 0.0006200917, step = 44105 (2.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.4242\n",
      "INFO:tensorflow:loss = 0.0006332906, step = 44205 (2.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.1485\n",
      "INFO:tensorflow:loss = 0.00064647116, step = 44305 (2.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.559\n",
      "INFO:tensorflow:loss = 0.00030637765, step = 44405 (2.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.6762\n",
      "INFO:tensorflow:loss = 0.0006306121, step = 44505 (2.802 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.8169\n",
      "INFO:tensorflow:loss = 0.0005896856, step = 44605 (2.792 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.348\n",
      "INFO:tensorflow:loss = 0.00025708694, step = 44705 (2.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.0629\n",
      "INFO:tensorflow:loss = 3.0055757e-05, step = 44805 (2.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.1616\n",
      "INFO:tensorflow:loss = 0.0008207281, step = 44905 (2.844 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 45004 into ./mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0003238212.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x1fd5d2e0ba8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "mnist_classifier.train(input_fn=train_input_fn, steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-02-11-11:01:38\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_convnet_model\\model.ckpt-45004\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-11-11:01:39\n",
      "INFO:tensorflow:Saving dict for global step 45004: accuracy = 0.98866665, global_step = 45004, loss = 0.052339565\n",
      "{'accuracy': 0.98866665, 'loss': 0.052339565, 'global_step': 45004}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and print results\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_cv},\n",
    "    y=y_cv,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-02-11-10:52:50\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_convnet_model\\model.ckpt-35004\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-11-10:52:50\n",
      "INFO:tensorflow:Saving dict for global step 35004: accuracy = 0.98466665, global_step = 35004, loss = 0.06955772\n",
      "{'accuracy': 0.98466665, 'loss': 0.06955772, 'global_step': 35004}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and print results\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_te},\n",
    "    y=y_te,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "test_results = mnist_classifier.evaluate(input_fn=test_input_fn)\n",
    "\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
